---
title: 'The Trailing Slash Tax: Why Missing a / Costs You 60% Performance'
description: 'A deep dive into how GitHub Pages handles trailing slashes, the hidden redirect cost, and why every millisecond matters for user experience'
date: 2025-10-28
tags: ['web-performance', 'github-pages']
authors: ['cduruk']
draft: false
---

import Callout from '@/components/Callout.astro'

I was browsing my own blog on my phone when I noticed something odd: some pages loaded instantly, while others had a barely perceptible delay. Even stranger, those slower pages had a subtle font flicker as they loaded.

The really surprising part? GitHub Pages felt *faster* than my local development server on those fast pages. That didn't make sense—local development should be instant, even if Astro is doing on-demand rendering.

The font flicker was the clue. Fonts don't flicker unless the browser is making multiple requests. That meant one thing: **redirects**.

Sure enough, every URL without a trailing slash was triggering a 301 redirect. That single missing character was costing me **60% in page load performance**.

## The Problem

GitHub Pages (and many static site generators) treat directories and files differently:

- `/posts/my-article` → 301 redirect → `/posts/my-article/`
- `/posts/my-article/` → 200 OK (direct response)

This isn't new—[Marc Gauthier documented the same issue back in 2016](https://marcgg.com/blog/2016/03/14/github-pages-jekyll/) with Jekyll. But the redirect cost is real, and I wanted to measure it.

## The Evidence

I ran timing tests against this very site using `curl`. Here's what happens when you request a URL without a trailing slash:

```bash
$ curl -I https://justoffbyone.com/posts/measuring-engineering-productivity

HTTP/2 301
server: GitHub.com
location: https://justoffbyone.com/posts/measuring-engineering-productivity/
cache-control: max-age=600
x-github-request-id: 33B9:3253BC:B93DB6:D68DCC:6900C8EA
```

And with a trailing slash:

```bash
$ curl -I https://justoffbyone.com/posts/measuring-engineering-productivity/

HTTP/2 200
server: GitHub.com
content-type: text/html; charset=utf-8
cache-control: max-age=600
content-length: 70127
```

The first request gets a `301 Moved Permanently` response, forcing the browser to make a second request. The second request goes straight to the content.

## The Performance Impact

Let's measure the actual cost. I created a curl timing format to track each phase of the request:

<Callout variant="theorem">
  $$
    \text{Total Latency} = \text{DNS} + \text{TCP} + \text{TLS} + \text{Redirect} + \text{TTFB}
  $$
</Callout>

### Detailed Timing Breakdown

**Without Trailing Slash (with redirect):**
```
    time_namelookup:  0.002011s
       time_connect:  0.052185s
    time_appconnect:  0.068896s
   time_pretransfer:  0.069005s
      time_redirect:  0.079601s
 time_starttransfer:  0.089141s
                    ----------
         time_total:  0.101227s
           num_redirects:  1
```

**With Trailing Slash (direct):**
```
    time_namelookup:  0.001993s
       time_connect:  0.008183s
    time_appconnect:  0.022139s
   time_pretransfer:  0.022189s
      time_redirect:  0.000000s
 time_starttransfer:  0.033561s
                    ----------
         time_total:  0.045192s
           num_redirects:  0
```

### The Results (5-Run Average)

| Metric | Without `/` | With `/` | Overhead |
|--------|-------------|----------|----------|
| Time to First Byte | 89ms | 34ms | +55ms |
| Total Time | **93ms** | **55ms** | **+38ms** |
| Redirects | 1 | 0 | +1 request |
| **Performance Cost** | | | **+60%** |

<Callout variant="tip">
  That's right: missing a single character makes your page **60% slower**.
</Callout>

## Why This Annoyed Me

I was kind of surprised that a mere 38ms felt so different. Here's my guess on why it seemed to matter that much. First of all, we know from cog sci research that humans can detect delays up to 100ms. 38ms isn't that slow, but it's almost half of that 100ms budget. And it's very likely that with that 40ms, we went from imperceptible to perceptible delay.

Also, these tests were from a fast connection in New York. On 4G or 3G? You're looking at 200-500ms per redirect. And if you're far from GitHub's CDN edge, that cost multiplies.

But mostly, it was that font flicker. Once you see it, you can't unsee it.

## The Real-World Cascade

Here's what happens when a user clicks a link to your blog post:

### Without Trailing Slash
```
1. DNS lookup: github.com → 2ms
2. TCP handshake → 50ms
3. TLS handshake → 17ms
4. Request: GET /posts/article
5. Response: 301 Redirect → 20ms
6. Follow redirect
7. Request: GET /posts/article/ → 35ms
8. Response: 200 OK
Total: ~124ms
```

### With Trailing Slash
```
1. DNS lookup: github.com → 2ms
2. TCP handshake → 8ms
3. TLS handshake → 14ms
4. Request: GET /posts/article/
5. Response: 200 OK → 34ms
Total: ~58ms
```

The redirect forces a **full round trip** through the network stack before you can even start downloading the page.

## Testing Your Own Site

I created a script to test any URL for trailing slash behavior. The full script is available in [this repository](test-trailing-slash.sh) and includes HTTP header inspection, detailed timing breakdowns, and multi-run averaging.

Here's the core logic that measures the performance difference:

```bash
#!/bin/bash

# Create curl timing format
TIMING_FORMAT=$(mktemp)
cat > "$TIMING_FORMAT" << 'EOF'
{
  "dns_lookup": %{time_namelookup},
  "tcp_connection": %{time_connect},
  "tls_handshake": %{time_appconnect},
  "time_redirect": %{time_redirect},
  "time_to_first_byte": %{time_starttransfer},
  "total_time": %{time_total},
  "num_redirects": %{num_redirects}
}
EOF

# Test both URLs multiple times
URL_WITHOUT_SLASH="$1"
URL_WITH_SLASH="${1}/"

declare -a times_without=()
declare -a times_with=()

for i in {1..5}; do
    time_without=$(curl -L -w "%{time_total}" -o /dev/null -s "$URL_WITHOUT_SLASH")
    times_without+=($time_without)

    time_with=$(curl -L -w "%{time_total}" -o /dev/null -s "$URL_WITH_SLASH")
    times_with+=($time_with)
done

# Calculate averages and difference
avg_without=$(printf '%s\n' "${times_without[@]}" | awk '{sum+=$1} END {print sum/NR}')
avg_with=$(printf '%s\n' "${times_with[@]}" | awk '{sum+=$1} END {print sum/NR}')
difference=$(echo "$avg_without - $avg_with" | bc)
percentage=$(echo "scale=1; ($difference / $avg_with) * 100" | bc)

echo "WITHOUT trailing slash: ${avg_without}s"
echo "WITH trailing slash:    ${avg_with}s"
echo "Performance cost:       ${percentage}% slower"
```

The `-L` flag tells curl to follow redirects, and the `-w` flag outputs timing information. By running multiple iterations, we get a more accurate average that accounts for network variability.

## Preventing the Problem

The solution isn't about "fixing" GitHub Pages—it will always redirect URLs without trailing slashes. The goal is to ensure your code never generates those incorrect URLs in the first place.

**For Astro (this blog):**
```javascript
// astro.config.mjs
export default defineConfig({
  trailingSlash: 'always'
})
```

This doesn't eliminate redirects in production, but it ensures consistency between development and production. More importantly, in development Astro will show you a warning page when you request a URL without a trailing slash, catching the issue before it ships.

### Auditing Existing Links

Configuration alone isn't enough—you also need to audit your existing content. I took two approaches:

**1. Created a helper function** to wrap all link generation:

```typescript
export function ensureTrailingSlash(href: string): string {
  // Don't modify empty strings, external URLs, or anchor-only links
  if (!href || href.startsWith('http') || href.startsWith('#')) {
    return href
  }

  // Handle query strings and hash fragments
  const queryIndex = href.indexOf('?')
  const hashIndex = href.indexOf('#')

  // ... logic to preserve query strings and hash fragments

  // Don't add trailing slash to files with extensions
  if (pathPart.endsWith('/') || /\.[a-z]+$/i.test(pathPart)) {
    return href
  }

  return `${pathPart}/`
}
```

Now every navigation component uses this function, ensuring all generated links have trailing slashes. It handles edge cases like query strings (`/search/?q=test`), hash fragments (`/posts/#top`), and file extensions (`/rss.xml`).

**2. Added an automated test** to catch hardcoded links in blog posts:

```typescript
it('should have trailing slashes on all internal /posts/ links', async () => {
  const mdxFiles = globSync('src/content/blog/**/*.mdx')

  for (const file of mdxFiles) {
    const content = readFileSync(file, 'utf-8')
    const lines = content.split('\n')

    lines.forEach((line, index) => {
      // Match internal /posts/ links without trailing slash
      const regex = /\/posts\/([^/\s)]+)\)/g
      // ... report any violations
    })
  }
})
```

This test runs on every commit and catches any hardcoded links in my MDX files that are missing trailing slashes. It's saved me multiple times from accidentally introducing redirects.

## The Takeaway

Honestly? I did this because it's fun to optimize things. But I was pleasantly surprised by how much faster the site feels now. I haven't dug too deeply into it, but I suspect that when all your links return proper 200s, the browser gets better at prefetching or caching across resources.

The numbers show a 60% improvement, but the real win is that font flicker is gone and navigation feels instant. Sometimes the small details compound into something noticeable.

---

*All tests were conducted from New York (EWR) against justoffbyone.com hosted on GitHub Pages. Results will vary based on geography, network conditions, and hosting setup.*
